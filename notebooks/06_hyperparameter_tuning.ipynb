{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Training Set Shape After SMOTE: (8278, 20)\n",
      "\n",
      "ðŸŽ¯ Tuned Random Forest Performance:\n",
      "Accuracy: 0.7736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.83      0.84      1035\n",
      "         1.0       0.57      0.62      0.59       374\n",
      "\n",
      "    accuracy                           0.77      1409\n",
      "   macro avg       0.71      0.72      0.72      1409\n",
      "weighted avg       0.78      0.77      0.78      1409\n",
      "\n",
      "\n",
      "ðŸ”¥ Tuned XGBoost Performance:\n",
      "Accuracy: 0.7395\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.72      0.80      1035\n",
      "         1.0       0.51      0.79      0.62       374\n",
      "\n",
      "    accuracy                           0.74      1409\n",
      "   macro avg       0.71      0.76      0.71      1409\n",
      "weighted avg       0.80      0.74      0.75      1409\n",
      "\n",
      "\n",
      "âœ… Hyperparameter Tuning Completed & Best Models Saved!\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Step 1: Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# Set visualization style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ðŸ“Œ Step 2: Load Preprocessed Data\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "X_test = pd.read_csv(\"../data/processed/X_test.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").values.ravel()\n",
    "y_test = pd.read_csv(\"../data/processed/y_test.csv\").values.ravel()\n",
    "\n",
    "# ðŸ“Œ Step 3: Apply SMOTE for Balancing Data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"New Training Set Shape After SMOTE: {X_train_resampled.shape}\")\n",
    "\n",
    "# ðŸ“Œ Step 4: Define Hyperparameter Grid for Random Forest\n",
    "rf_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [5, 10, 15],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "}\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "grid_rf = GridSearchCV(rf_model, rf_params, cv=3, scoring=\"f1\", n_jobs=-1)\n",
    "grid_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# ðŸ“Œ Step 5: Train the Best Random Forest Model\n",
    "best_rf = grid_rf.best_estimator_\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nðŸŽ¯ Tuned Random Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "# ðŸ“Œ Step 6: Define Hyperparameter Grid for XGBoost\n",
    "xgb_params = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42, scale_pos_weight=2)\n",
    "grid_xgb = GridSearchCV(xgb_model, xgb_params, cv=3, scoring=\"f1\", n_jobs=-1)\n",
    "grid_xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# ðŸ“Œ Step 7: Train the Best XGBoost Model\n",
    "best_xgb = grid_xgb.best_estimator_\n",
    "y_pred_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nðŸ”¥ Tuned XGBoost Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_xgb):.4f}\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "\n",
    "# ðŸ“Œ Step 8: Save the Best Performing Model\n",
    "joblib.dump(best_rf, \"../models/best_random_forest.pkl\")\n",
    "joblib.dump(best_xgb, \"../models/best_xgboost.pkl\")\n",
    "\n",
    "print(\"\\nâœ… Hyperparameter Tuning Completed & Best Models Saved!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
